{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd78f25-0f08-4525-a4fb-72b856ffdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccce6d-3dae-44d4-92bc-5098f5856c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration phase, which features, balancing techniques and which model perfrom best. in a nested 5 fold cross validation\n",
    "\n",
    "class FeatureBlockHandler:\n",
    "    def __init__(self, demographic_columns, health_lifestyle_columns, \n",
    "                 personality_columns, politics_values_columns):\n",
    "        self.blocks = {\n",
    "            'demographic': demographic_columns,\n",
    "            'health_lifestyle': health_lifestyle_columns,\n",
    "            'personality': personality_columns,\n",
    "            'politics_values': politics_values_columns,\n",
    "            'all': demographic_columns + health_lifestyle_columns + \n",
    "                  personality_columns + politics_values_columns\n",
    "        }\n",
    "        \n",
    "    def get_block(self, X, block_type):\n",
    "        \"\"\"Returns the features for the specified block.\"\"\"\n",
    "        if block_type not in self.blocks:\n",
    "            raise ValueError(f\"Block type must be one of {list(self.blocks.keys())}\")\n",
    "        return X[self.blocks[block_type]]\n",
    "\n",
    "    def get_selected_features(self, X, y, method='none', threshold='median'):\n",
    "        \"\"\"\n",
    "        Apply feature selection on ALL features using various methods.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas DataFrame\n",
    "            Input features (all features, not block-specific)\n",
    "        y : array-like\n",
    "            Target variable\n",
    "        method : str\n",
    "            'none', 'lasso', or 'rf'\n",
    "        threshold : str or float\n",
    "            Threshold for feature selection, 'median' or float value\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        selected_features : list\n",
    "            List of selected feature names\n",
    "        selector : object\n",
    "            Fitted selector object (if applicable)\n",
    "        \"\"\"\n",
    "        if method == 'none':\n",
    "            return list(X.columns), None\n",
    "            \n",
    "        elif method == 'lasso':\n",
    "            selector = SelectFromModel(\n",
    "                Lasso(random_state=42),\n",
    "                threshold=threshold\n",
    "            )\n",
    "            \n",
    "        elif method == 'rf':\n",
    "            selector = SelectFromModel(\n",
    "                RandomForestClassifier(random_state=42),\n",
    "                threshold=threshold\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Method must be one of ['none', 'lasso', 'rf']\")\n",
    "        \n",
    "        # Fit selector and get feature mask\n",
    "        selector.fit(X, y)\n",
    "        feature_mask = selector.get_support()\n",
    "        \n",
    "        # Get selected feature names\n",
    "        selected_features = X.columns[feature_mask].tolist()\n",
    "        \n",
    "        return selected_features, selector\n",
    "\n",
    "def find_best_combination(self, X, y, feature_blocks):\n",
    "    \"\"\"\n",
    "    Find the best combination comparing:\n",
    "    1. Different blocks without feature selection\n",
    "    2. Feature selection methods (lasso, rf) on all features\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=self.random_state\n",
    "    )\n",
    "    \n",
    "    best_score = -np.inf\n",
    "    best_config = None\n",
    "    results = {}\n",
    "    \n",
    "    # Define approaches to compare\n",
    "    approaches = [\n",
    "        # Block-based approaches (no feature selection)\n",
    "        {'type': 'block', 'name': 'demographic'},\n",
    "        {'type': 'block', 'name': 'health_lifestyle'},\n",
    "        {'type': 'block', 'name': 'personality'},\n",
    "        {'type': 'block', 'name': 'politics_values'},\n",
    "        # Feature selection approaches (on all features)\n",
    "        {'type': 'feature_selection', 'name': 'lasso'},\n",
    "        {'type': 'feature_selection', 'name': 'rf'}\n",
    "    ]\n",
    "    \n",
    "    # Outer CV for honest performance estimation\n",
    "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, \n",
    "                             random_state=self.random_state)\n",
    "    \n",
    "    for balancing in ['undersampling', 'oversampling', 'smote']:\n",
    "        print(f\"\\nTrying balancing method: {balancing}\")\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(outer_cv.split(X_train, y_train)):\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # Apply balancing\n",
    "            X_balanced, y_balanced = self.apply_balancing(\n",
    "                X_fold_train, y_fold_train, balancing\n",
    "            )\n",
    "            \n",
    "            for approach in approaches:\n",
    "                approach_type = approach['type']\n",
    "                approach_name = approach['name']\n",
    "                \n",
    "                if approach_type == 'block':\n",
    "                    # Use block-based features\n",
    "                    X_features = feature_blocks.get_block(X_balanced, approach_name)\n",
    "                    X_val_features = feature_blocks.get_block(X_fold_val, approach_name)\n",
    "                else:  # feature_selection\n",
    "                    # Apply feature selection on all features\n",
    "                    selected_features, selector = feature_blocks.get_selected_features(\n",
    "                        X_balanced, y_balanced, method=approach_name\n",
    "                    )\n",
    "                    X_features = X_balanced[selected_features]\n",
    "                    X_val_features = X_fold_val[selected_features]\n",
    "                \n",
    "                # Try different models with the selected features\n",
    "                for model_name, model in self.models.items():\n",
    "                    print(f\"  Trying {approach_type}:{approach_name} with {model_name}\")\n",
    "                    \n",
    "                    grid_search = GridSearchCV(\n",
    "                        model, \n",
    "                        self.model_params[model_name],\n",
    "                        cv=3,\n",
    "                        scoring='f1'\n",
    "                    )\n",
    "                    \n",
    "                    grid_search.fit(X_features, y_balanced)\n",
    "                    y_pred = grid_search.predict(X_val_features)\n",
    "                    score = f1_score(y_fold_val, y_pred)\n",
    "                    \n",
    "                    config_name = f\"{balancing}_{approach_type}_{approach_name}_{model_name}\"\n",
    "                    if config_name not in results:\n",
    "                        results[config_name] = []\n",
    "                    results[config_name].append(score)\n",
    "                    \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_config = {\n",
    "                            'balancing': balancing,\n",
    "                            'approach_type': approach_type,\n",
    "                            'approach_name': approach_name,\n",
    "                            'model': model_name,\n",
    "                            'params': grid_search.best_params_\n",
    "                        }\n",
    "    \n",
    "    # Calculate average scores across folds\n",
    "    for config in results:\n",
    "        results[config] = np.mean(results[config])\n",
    "    \n",
    "    return best_config, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc9215-919d-4963-aa61-fa05d1135f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=self.random_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee208ce4-256b-47e9-be62-5b999c4ea694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with the best configuration with cross validation. get the folds cross validation scores.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_final_model(self, X, y, best_config, feature_blocks):\n",
    "    # Apply balancing\n",
    "    X_balanced, y_balanced = self.apply_balancing(X, y, best_config['balancing'])\n",
    "\n",
    "    # Get features\n",
    "    if best_config['approach_type'] == 'block':\n",
    "        X_features = feature_blocks.get_block(X_balanced, best_config['approach_name'])\n",
    "    else:  # feature_selection\n",
    "        selected_features, _ = feature_blocks.get_selected_features(\n",
    "            X_balanced, y_balanced, method=best_config['approach_name']\n",
    "        )\n",
    "        X_features = X_balanced[selected_features]\n",
    "\n",
    "    # Train final model with best parameters\n",
    "    final_model = self.models[best_config['model']]\n",
    "    final_model.set_params(**best_config['params'])\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    scores = cross_val_score(final_model, X_features, y_balanced, cv=5, scoring='f1')\n",
    "    test_score = np.mean(scores)\n",
    "\n",
    "    # Fit final model on all data\n",
    "    final_model.fit(X_features, y_balanced)\n",
    "\n",
    "    return final_model, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d2753-f69e-41b8-9ef2-ff45237d5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i would get a list of F1-score values from cross_val_score, one for each fold of the cross-validation.\n",
    "#i could take the mean of these scores to get the overall cross- validated F1-score of the final model.\n",
    "scores=cross_val_score(final_model, X_features, y_balanced, cv=5, scoring='f1')\n",
    "test-score=np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa17514-f946-4454-b3f2-7c8382d71f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the train_final_model funstion returns the final model object( final_model). in addition to the cv metrics i could evaluate the final model on hold-out test set\n",
    "# to see if model generalizes well.\n",
    "#By comparing the cross-validated performance and the test set performance, you can get a sense of how well the model is expected to perform in the real world. If there's a significant gap between the two, it may indicate issues like overfitting that need to be addressed.\n",
    "y_pred = final_model.predict(X_test_features)\n",
    "test_set_f1 = f1_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
